{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d17096-844a-4c1b-9255-ba6186720e82",
   "metadata": {},
   "source": [
    "# Base S3 Bucket preparation and training data download to Jupyter Notebook Pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3736fe2-3517-44f9-9635-1ddfb34c0594",
   "metadata": {},
   "source": [
    "This Notebook sets the scene for the base bucket and then downloads available x-ray images for training to the pod for the execution of the ML training notebook.\n",
    "\n",
    "Note! The actual upload of train/test/validation files is outside the scope of this notebook. Plese use either AWS console or aws cli to upload the dataset to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a38ce02-ee0d-400a-ad4f-c7db350f4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.8/site-packages (1.17.11)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/app-root/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.11 in /opt/app-root/lib/python3.8/site-packages (from boto3) (1.20.95)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/app-root/lib/python3.8/site-packages (from boto3) (0.3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.11->boto3) (1.26.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.11->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.11->boto3) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0b0178-4ea8-44e9-8271-d81df43b7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct keys to S3 and not to the ODF storage instance from OCP4\n",
    "aws_access_key_id = 'your_key_id'\n",
    "aws_secret_access_key = 'your_access_key'\n",
    "region_name = 'default' #default region for the profile e.g., us-east-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9f8bef-7862-4986-a3f0-7b72c8e19b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name):\n",
    "    location = {'LocationConstraint': region_name}\n",
    "    result = s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration=location)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9872c042-1915-46bc-a6e1-f837d867bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the list of existing buckets\n",
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id = aws_access_key_id,\n",
    "                  aws_secret_access_key = aws_secret_access_key,\n",
    "                  region_name = region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279b7a3-a46d-434c-872f-77fcc1d0c134",
   "metadata": {},
   "source": [
    "#### Uncomment the below to create the base bucket where the images are stored. \n",
    "Optionally, you can change the name of the bucket, though ensure to replace the new name in all instances where you use it (this file included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c854c911-927f-47ab-b261-5ba4dea7eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_bucket('ml-pneumonia-datasource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c6425e-d4ee-434d-8f40-1511e38e7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "  cluster-tws4r-289dz-image-registry-us-east-2-woscgptkqjgwywhvd\n",
      "  ml-pneumonia-datasource\n",
      "  nb.1634660370505.cluster-tws4r.tws4r.sandbox702.opentlc.com\n"
     ]
    }
   ],
   "source": [
    "response = s3.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f65d76-6e88-49a0-98e1-9f258d835174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dir(aws_access_key_id, aws_secret_access_key, region_name,  bucket, s3_prefix = '', local_base = ''):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - aws_access_key_id: The aws_access_key_id\n",
    "    - aws_secret_access_key: The aws_secret_access_key\n",
    "    - region_name: The region where the bucket was created\n",
    "    - bucket: s3 bucket with target contents\n",
    "    - s3_prefix: pattern to match in s3\n",
    "    - local_base: local path to folder in which to place files\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_resource = boto3.resource('s3',\n",
    "                             aws_access_key_id = aws_access_key_id,\n",
    "                             aws_secret_access_key = aws_secret_access_key,\n",
    "                             region_name = region_name)\n",
    "    \n",
    "    ml_ds_bucket = s3_resource.Bucket(bucket)\n",
    "    bucket_objects = ml_ds_bucket.objects.all()\n",
    "    \n",
    "    files = []\n",
    "    for item in bucket_objects:\n",
    "        files.append(item.key)\n",
    "\n",
    "    print(f'Downloading files...')\n",
    "    for file in tqdm.tqdm(files):\n",
    "        dest_pathname = os.path.join(local_base, file)\n",
    "        if not os.path.exists(os.path.dirname(dest_pathname)):\n",
    "            os.makedirs(os.path.dirname(dest_pathname))\n",
    "        ml_ds_bucket.download_file(file, dest_pathname)\n",
    "        \n",
    "    print(f'Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041a6f4-2cb8-4aca-a850-a3e83e197f9a",
   "metadata": {},
   "source": [
    "#### The below cell will download to this pod in the (new) dataset folder the contents of the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43f6caa-759b-47e8-8f27-18d76b46e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5856 [00:00<06:53, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5856/5856 [06:06<00:00, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_dir(aws_access_key_id = aws_access_key_id,\n",
    "              aws_secret_access_key = aws_secret_access_key,\n",
    "              region_name = region_name,\n",
    "              bucket = 'ml-pneumonia-datasource',\n",
    "              s3_prefix = '',\n",
    "              local_base = 'dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b05a27-0ba6-4231-a6bf-3bcf4c15c927",
   "metadata": {},
   "source": [
    "Final check to ensure the number of files matches the one from the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70cd17b-c64e-4f91-a723-546442e8c4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5894\n"
     ]
    }
   ],
   "source": [
    "!ls -lR dataset | wc -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
